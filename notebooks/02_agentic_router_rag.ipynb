{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agentic Router RAG with LangGraph\n",
    "\n",
    "In this notebook, we'll build an agentic RAG system that can route queries to the appropriate data source, including web search for current information. This solves some of the limitations we saw in the basic RAG approach.\n",
    "\n",
    "## What is Agentic Router RAG?\n",
    "\n",
    "Router RAG adds an intelligent routing layer that:\n",
    "1. **Analyzes the query** to understand the user's intent\n",
    "2. **Routes to the appropriate data source** (catalog, FAQ, troubleshooting, or web search)\n",
    "3. **Retrieves relevant documents** from the correct collection or searches the web\n",
    "4. **Generates contextual answers** using only relevant information\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will:\n",
    "- Understand how query routing works in RAG systems\n",
    "- Connect to multiple ChromaDB collections, for different types of data\n",
    "- Integrate web search for current information using Tavily\n",
    "- Build a router node that classifies query intent\n",
    "- Create conditional workflows in LangGraph\n",
    "- Compare router RAG performance with basic RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports\n",
    "\n",
    "We'll need additional imports for the router functionality and structured output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All imports successful!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from typing import List, TypedDict, Literal\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_community.retrievers import TavilySearchAPIRetriever\n",
    "from langgraph.graph import StateGraph, END\n",
    "from pydantic import BaseModel, Field\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "print(\"All imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Setup\n",
    "\n",
    "Check for required environment variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API key found!\n",
      "Tavily API key found!\n"
     ]
    }
   ],
   "source": [
    "# Check if OpenAI API key is available\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "if not openai_api_key:\n",
    "    raise ValueError(\"OPENAI_API_KEY environment variable is required\")\n",
    "\n",
    "# Check if Tavily API key is available\n",
    "tavily_api_key = os.getenv(\"TAVILY_API_KEY\")\n",
    "if not tavily_api_key:\n",
    "    raise ValueError(\"TAVILY_API_KEY environment variable is required for web search functionality\")\n",
    "\n",
    "print(\"OpenAI API key found!\")\n",
    "print(\"Tavily API key found!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding Our Separate Collections\n",
    "\n",
    "Unlike the basic RAG notebook, we now have three separate ChromaDB collections:\n",
    "\n",
    "1. **techmart_catalog**: Product information, specifications, and descriptions\n",
    "2. **techmart_faq**: Customer service questions about shipping, returns, policies\n",
    "3. **techmart_troubleshooting**: Technical support guides and solutions\n",
    "\n",
    "Each collection contains documents optimized for its specific domain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to Separate ChromaDB Collections\n",
    "\n",
    "We'll create three separate vector store instances, one for each collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to separate ChromaDB collections at: ../vector_store/chroma_db_separate\n",
      "Catalog collection: 325 documents\n",
      "FAQ collection: 50 documents\n",
      "Troubleshooting collection: 154 documents\n"
     ]
    }
   ],
   "source": [
    "# Initialize embeddings model (same as used during ingestion)\n",
    "embeddings = OpenAIEmbeddings(\n",
    "    model=os.getenv(\"OPENAI_EMBEDDING_MODEL\", \"text-embedding-3-small\"),\n",
    "    api_key=openai_api_key\n",
    ")\n",
    "\n",
    "# Path to the separate ChromaDB collections\n",
    "chroma_db_path = Path(\"..\") / \"vector_store\" / \"chroma_db_separate\"\n",
    "\n",
    "# Connect to each collection\n",
    "catalog_store = Chroma(\n",
    "    collection_name=\"techmart_catalog\",\n",
    "    embedding_function=embeddings,\n",
    "    persist_directory=str(chroma_db_path)\n",
    ")\n",
    "\n",
    "faq_store = Chroma(\n",
    "    collection_name=\"techmart_faq\",\n",
    "    embedding_function=embeddings,\n",
    "    persist_directory=str(chroma_db_path)\n",
    ")\n",
    "\n",
    "troubleshooting_store = Chroma(\n",
    "    collection_name=\"techmart_troubleshooting\",\n",
    "    embedding_function=embeddings,\n",
    "    persist_directory=str(chroma_db_path)\n",
    ")\n",
    "\n",
    "print(f\"Connected to separate ChromaDB collections at: {chroma_db_path}\")\n",
    "print(f\"Catalog collection: {catalog_store._collection.count()} documents\")\n",
    "print(f\"FAQ collection: {faq_store._collection.count()} documents\")\n",
    "print(f\"Troubleshooting collection: {troubleshooting_store._collection.count()} documents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Each Collection\n",
    "\n",
    "Let's verify each collection contains the expected type of information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CATALOG Collection - Query: 'laptop with good performance'\n",
      "============================================================\n",
      "Document 1: product_id: SKU232 | name: ZenithBook 11 Evo | category: Laptop | price: 1299.0 | short_desc: A sleek 15-inch ultrabook with Intel Core i7, 16GB RAM, ...\n",
      "Document 2: product_id: SKU050 | name: ZenithBook 15 Evo | category: Laptop | price: 1299.0 | short_desc: 15.6\" ultralight laptop with Intel Core i7, 16GB RAM, sp...\n",
      "------------------------------------------------------------\n",
      "\n",
      "FAQ Collection - Query: 'shipping times'\n",
      "============================================================\n",
      "Document 1: question: How long does standard shipping take within the continental US? | answer: Standard shipping typically arrives in 3–5 business days once your...\n",
      "Document 2: question: Do you offer next‑day delivery for laptops? | answer: Yes, we offer overnight delivery on all in‑stock laptops for orders placed before 2 p....\n",
      "------------------------------------------------------------\n",
      "\n",
      "TROUBLESHOOTING Collection - Query: 'battery drain problem'\n",
      "============================================================\n",
      "Document 1: issue_title: UltraBook Pro battery drains quickly | product_id: SKU001 | symptoms: Battery indicator drops from 100 % to 70 % in under an hour of web ...\n",
      "Document 2: issue_title: Zenith X5 battery drains overnight | product_id: SKU014 | symptoms: Battery drops 20 % while idle on standby. | steps: 1. Disable ‘Always...\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Test each collection with a relevant query\n",
    "test_queries = {\n",
    "    \"catalog\": \"laptop with good performance\",\n",
    "    \"faq\": \"shipping times\", \n",
    "    \"troubleshooting\": \"battery drain problem\"\n",
    "}\n",
    "\n",
    "stores = {\n",
    "    \"catalog\": catalog_store,\n",
    "    \"faq\": faq_store,\n",
    "    \"troubleshooting\": troubleshooting_store\n",
    "}\n",
    "\n",
    "for collection_name, query in test_queries.items():\n",
    "    store = stores[collection_name]\n",
    "    results = store.similarity_search(query, k=2)\n",
    "    \n",
    "    print(f\"\\n{collection_name.upper()} Collection - Query: '{query}'\")\n",
    "    print(\"=\" * 60)\n",
    "    for i, doc in enumerate(results, 1):\n",
    "        print(f\"Document {i}: {doc.page_content[:150]}...\")\n",
    "    print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Language Models\n",
    "\n",
    "We'll use separate OpenAI models for routing decisions and answer generation. This flexibility in an agentic RAG workflow gives us an opportunity to optimise cost and latency while making sure the performance of the overall system remains optimal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer generation language model initialized: gpt-4.1\n",
      "Routing language model initialized: gpt-4o-mini\n"
     ]
    }
   ],
   "source": [
    "# Initialize the language model for generating answers\n",
    "generation_llm = ChatOpenAI(\n",
    "    model=os.getenv(\"OPENAI_MODEL\", \"gpt-4o\"),\n",
    "    api_key=openai_api_key\n",
    ")\n",
    "print(f\"Answer generation language model initialized: {generation_llm.model_name}\")\n",
    "\n",
    "# Initialize the language model for routing decisions\n",
    "routing_llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    api_key=openai_api_key\n",
    ")\n",
    "print(f\"Routing language model initialized: {routing_llm.model_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Router Output Schema\n",
    "\n",
    "We'll use Pydantic to define the structure of our router's output, ensuring it always returns one of our three valid collection names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Router output schema defined!\n"
     ]
    }
   ],
   "source": [
    "class RouterOutput(BaseModel):\n",
    "    \"\"\"Output schema for the query router.\"\"\"\n",
    "    chosen_collection: Literal[\"catalog\", \"faq\", \"troubleshooting\", \"web_search\"] = Field(\n",
    "        description=\"The collection to route the query to based on intent\"\n",
    "    )\n",
    "    reasoning: str = Field(\n",
    "        description=\"Brief explanation of why this collection was chosen\"\n",
    "    )\n",
    "\n",
    "print(\"Router output schema defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Router Prompt Template\n",
    "\n",
    "This prompt will guide the LLM to classify queries and route them to the appropriate collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Router prompt and chain created!\n"
     ]
    }
   ],
   "source": [
    "# Router prompt for query classification\n",
    "router_prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"You are a query router for TechMart, an electronics retailer. \n",
    "Analyze the user's query and determine which collection contains the most relevant information.\n",
    "\n",
    "Collections available:\n",
    "- **catalog**: Product information, specifications recommendations, comparisons, and technical details about laptops, desktops, monitors, and accessories\n",
    "- **faq**: Customer service questions about shipping, delivery, returns, warranties, policies, and general business operations\n",
    "- **troubleshooting**: Technical support guides, problem diagnosis, step-by-step solutions, and fixes for product issues that TechMart sells\n",
    "- **web_search**: For questions about issues that are not covered in our internal troubleshooting database, or for getting the latest information about software, hardware, drivers, or anything that require current information from the internet\n",
    "\n",
    "Query: {query}\n",
    "\n",
    "Instructions:\n",
    "- Choose the single most appropriate collection for this query\n",
    "- If a query spans multiple domains, choose the primary intent\n",
    "- Use web_search for troubleshooting issues that are likely not covered in our limited internal database\n",
    "- Provide brief reasoning for your choice\n",
    "\n",
    "Examples:\n",
    "- \"What laptops do you recommend?\" → catalog (product recommendations)\n",
    "- \"How long does shipping take?\" → faq (shipping policy)\n",
    "- \"My laptop won't turn on\" → troubleshooting (common technical problem we likely have guides for)\n",
    "- \"Best gaming desktop under $2000\" → catalog (product search with specs)\n",
    "- \"Can I return a monitor?\" → faq (return policy)\n",
    "- \"Headphones keep disconnecting\" → troubleshooting (common connectivity issue)\n",
    "- \"Windows 11 blue screen error 0x0000007E\" → web_search (specific system error requiring current information)\n",
    "- \"How to fix Chrome crashes on latest macOS\" → web_search (software issue needing current solutions)\n",
    "- \"Latest NVIDIA driver causing display issues\" → web_search (current driver problem not in our database)\n",
    "- \"WiFi adapter not working after Windows update\" → web_search (current OS compatibility issue)\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "# Create router chain with structured output\n",
    "router_chain = router_prompt | routing_llm.with_structured_output(RouterOutput)\n",
    "\n",
    "print(\"Router prompt and chain created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the Router\n",
    "\n",
    "Let's test our router with different types of queries to see how it classifies them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Router Decisions (Including Web Search):\n",
      "======================================================================\n",
      "Query: Tell me about the UltraBook battery\n",
      "  → Collection: catalog\n",
      "  → Reasoning: The query asks for information about the UltraBook battery, which falls under product specifications and details that are available in the catalog.\n",
      "\n",
      "Query: How long does international shipping take?\n",
      "  → Collection: faq\n",
      "  → Reasoning: The query asks about the duration of international shipping, which relates directly to shipping policies commonly covered in FAQs.\n",
      "\n",
      "Query: Laptop battery drains too quickly\n",
      "  → Collection: troubleshooting\n",
      "  → Reasoning: The query relates to a common technical problem with laptops, specifically about battery performance. This falls under troubleshooting as it seeks solutions or diagnoses for the issue of a laptop battery draining quickly.\n",
      "\n",
      "Query: Windows 11 blue screen error 0x0000007E\n",
      "  → Collection: web_search\n",
      "  → Reasoning: The query pertains to a specific Windows 11 blue screen error, which is likely to require recent information and solutions that may not be covered in TechMart's internal troubleshooting database.\n",
      "\n",
      "Query: What's the latest Nvidia GPU for gaming?\n",
      "  → Collection: web_search\n",
      "  → Reasoning: The query is about the latest Nvidia GPU for gaming, which requires current information that may not be available in our internal database.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test queries for each collection type including web search\n",
    "test_router_queries = [\n",
    "    \"Tell me about the UltraBook battery\",\n",
    "    \"How long does international shipping take?\",\n",
    "    \"Laptop battery drains too quickly\",\n",
    "    \"Windows 11 blue screen error 0x0000007E\",\n",
    "    \"What's the latest Nvidia GPU for gaming?\",\n",
    "]\n",
    "\n",
    "print(\"Testing Router Decisions (Including Web Search):\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for query in test_router_queries:\n",
    "    result = router_chain.invoke({\"query\": query})\n",
    "    print(f\"Query: {query}\")\n",
    "    print(f\"  → Collection: {result.chosen_collection}\")\n",
    "    print(f\"  → Reasoning: {result.reasoning}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define State for Router RAG\n",
    "\n",
    "Our state needs to track the query, routing decision, retrieved documents, and final answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Router RAG state defined!\n"
     ]
    }
   ],
   "source": [
    "class RouterRAGState(TypedDict):\n",
    "    \"\"\"State for our Router RAG workflow.\"\"\"\n",
    "    query: str\n",
    "    chosen_collection: str\n",
    "    routing_reasoning: str\n",
    "    retrieved_docs: List[Document]\n",
    "    answer: str\n",
    "\n",
    "print(\"Router RAG state defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Router Node\n",
    "\n",
    "The router node analyzes the query and determines which collection to search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Router node created!\n"
     ]
    }
   ],
   "source": [
    "def query_router(state: RouterRAGState) -> RouterRAGState:\n",
    "    \"\"\"Route query to the appropriate collection based on intent.\"\"\"\n",
    "    query = state[\"query\"]\n",
    "    \n",
    "    # Use the router chain to classify the query\n",
    "    router_result = router_chain.invoke({\"query\": query})\n",
    "    \n",
    "    print(f\"Router Decision: {router_result.chosen_collection}\")\n",
    "    print(f\"Reasoning: {router_result.reasoning}\")\n",
    "    \n",
    "    return {\n",
    "        \"chosen_collection\": router_result.chosen_collection,\n",
    "        \"routing_reasoning\": router_result.reasoning\n",
    "    }\n",
    "\n",
    "print(\"Router node created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Retrieve Nodes\n",
    "\n",
    "We'll create separate retrieve nodes for each collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Initialize Tavily retriever for web search\ntavily_retriever = TavilySearchAPIRetriever(\n    api_key=tavily_api_key,\n    k=5,  # Number of search results to return\n    include_generated_answer=False,\n    include_raw_content=False\n)\n\ndef retrieve_from_catalog(state: RouterRAGState) -> RouterRAGState:\n    \"\"\"Retrieve documents from the product catalog.\"\"\"\n    query = state[\"query\"]\n    retrieved_docs = catalog_store.similarity_search(query, k=5)\n    \n    # Print first 100 characters of each retrieved document with source\n    for i, doc in enumerate(retrieved_docs, 1):\n        source = doc.metadata.get('source', 'Unknown')\n        content_preview = doc.page_content[:100]\n        print(f\"  Doc {i} [{source}]: {content_preview}...\")\n    \n    print(f\"Retrieved {len(retrieved_docs)} documents from catalog\")\n    return {\"retrieved_docs\": retrieved_docs}\n\ndef retrieve_from_faq(state: RouterRAGState) -> RouterRAGState:\n    \"\"\"Retrieve documents from the FAQ collection.\"\"\"\n    query = state[\"query\"]\n    retrieved_docs = faq_store.similarity_search(query, k=5)\n    \n    # Print first 100 characters of each retrieved document with source\n    for i, doc in enumerate(retrieved_docs, 1):\n        source = doc.metadata.get('source', 'Unknown')\n        content_preview = doc.page_content[:100]\n        print(f\"  Doc {i} [{source}]: {content_preview}...\")\n    \n    print(f\"Retrieved {len(retrieved_docs)} documents from FAQ\")\n    return {\"retrieved_docs\": retrieved_docs}\n\ndef retrieve_from_troubleshooting(state: RouterRAGState) -> RouterRAGState:\n    \"\"\"Retrieve documents from the troubleshooting collection.\"\"\"\n    query = state[\"query\"]\n    retrieved_docs = troubleshooting_store.similarity_search(query, k=5)\n    \n    # Print first 100 characters of each retrieved document with source\n    for i, doc in enumerate(retrieved_docs, 1):\n        source = doc.metadata.get('source', 'Unknown')\n        content_preview = doc.page_content[:100]\n        print(f\"  Doc {i} [{source}]: {content_preview}...\")\n    \n    print(f\"Retrieved {len(retrieved_docs)} documents from troubleshooting\")\n    return {\"retrieved_docs\": retrieved_docs}\n\ndef retrieve_from_web_search(state: RouterRAGState) -> RouterRAGState:\n    \"\"\"Retrieve documents from web search using Tavily.\"\"\"\n    query = state[\"query\"]\n    \n    # Use Tavily to search the web (updated for LangChain 0.3+)\n    retrieved_docs = tavily_retriever.invoke(query)\n    \n    # Print first 100 characters of each retrieved document with source\n    for i, doc in enumerate(retrieved_docs, 1):\n        source = doc.metadata.get('source', 'Unknown')\n        content_preview = doc.page_content[:100]\n        print(f\"  Doc {i} [{source}]: {content_preview}...\")\n    \n    print(f\"Retrieved {len(retrieved_docs)} documents from web search\")\n    return {\"retrieved_docs\": retrieved_docs}\n\nprint(\"Retrieve nodes created!\")\nprint(\"Tavily web search retriever initialized!\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Generate Node\n",
    "\n",
    "The generate node creates answers using the retrieved documents from the selected collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate node created!\n"
     ]
    }
   ],
   "source": [
    "# Enhanced prompt template for router RAG\n",
    "generate_prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"You are a helpful assistant for TechMart, an electronics retailer.\n",
    "Use the following context from the {collection_type} database to answer the user's question accurately and helpfully.\n",
    "\n",
    "Context from {collection_type}:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Instructions:\n",
    "- Base your answer primarily on the provided context from the {collection_type} database\n",
    "- Be specific and helpful in your response\n",
    "- If the context doesn't contain enough information, say so clearly\n",
    "- Match your tone to the type of query (technical for troubleshooting, helpful for products, informative for policies)\n",
    "\n",
    "Answer:\"\"\"\n",
    ")\n",
    "\n",
    "def generate_answer(state: RouterRAGState) -> RouterRAGState:\n",
    "    \"\"\"Generate answer based on retrieved documents.\"\"\"\n",
    "    query = state[\"query\"]\n",
    "    collection_type = state[\"chosen_collection\"]\n",
    "    retrieved_docs = state[\"retrieved_docs\"]\n",
    "    \n",
    "    # Combine context from retrieved documents\n",
    "    context_text = \"\\n\\n\".join([\n",
    "        f\"Source: {doc.metadata.get('source', 'Unknown')}\\nContent: {doc.page_content}\"\n",
    "        for doc in retrieved_docs\n",
    "    ])\n",
    "    \n",
    "    # Generate response\n",
    "    messages = generate_prompt.invoke({\n",
    "        \"context\": context_text,\n",
    "        \"question\": query,\n",
    "        \"collection_type\": collection_type\n",
    "    })\n",
    "    \n",
    "    response = generation_llm.invoke(messages)\n",
    "    \n",
    "    print(f\"Generated answer using {collection_type} collection\")\n",
    "    return {\"answer\": response.content}\n",
    "\n",
    "print(\"Generate node created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the Router RAG Graph\n",
    "\n",
    "Now we'll create our LangGraph with conditional routing based on the router's decision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Router RAG graph compiled successfully!\n",
      "Workflow: router -> [conditional] retrieve_[collection|web_search] -> generate\n"
     ]
    }
   ],
   "source": [
    "# Define routing function for conditional edges\n",
    "def route_to_collection(state: RouterRAGState) -> str:\n",
    "    \"\"\"Determine which retrieve node to call based on router decision.\"\"\"\n",
    "    collection = state[\"chosen_collection\"]\n",
    "    return f\"retrieve_{collection}\"\n",
    "\n",
    "# Create the graph builder\n",
    "graph_builder = StateGraph(RouterRAGState)\n",
    "\n",
    "# Add all nodes\n",
    "graph_builder.add_node(\"router\", query_router)\n",
    "graph_builder.add_node(\"retrieve_catalog\", retrieve_from_catalog)\n",
    "graph_builder.add_node(\"retrieve_faq\", retrieve_from_faq)\n",
    "graph_builder.add_node(\"retrieve_troubleshooting\", retrieve_from_troubleshooting)\n",
    "graph_builder.add_node(\"retrieve_web_search\", retrieve_from_web_search)\n",
    "graph_builder.add_node(\"generate\", generate_answer)\n",
    "\n",
    "# Set entry point\n",
    "graph_builder.set_entry_point(\"router\")\n",
    "\n",
    "# Add conditional edges from router to appropriate retrieve node\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"router\",\n",
    "    route_to_collection,\n",
    "    {\n",
    "        \"retrieve_catalog\": \"retrieve_catalog\",\n",
    "        \"retrieve_faq\": \"retrieve_faq\", \n",
    "        \"retrieve_troubleshooting\": \"retrieve_troubleshooting\",\n",
    "        \"retrieve_web_search\": \"retrieve_web_search\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# All retrieve nodes go to generate\n",
    "graph_builder.add_edge(\"retrieve_catalog\", \"generate\")\n",
    "graph_builder.add_edge(\"retrieve_faq\", \"generate\")\n",
    "graph_builder.add_edge(\"retrieve_troubleshooting\", \"generate\")\n",
    "graph_builder.add_edge(\"retrieve_web_search\", \"generate\")\n",
    "\n",
    "# Generate is the end\n",
    "graph_builder.add_edge(\"generate\", END)\n",
    "\n",
    "# Compile the graph\n",
    "router_rag_graph = graph_builder.compile()\n",
    "\n",
    "print(\"Router RAG graph compiled successfully!\")\n",
    "print(\"Workflow: router -> [conditional] retrieve_[collection|web_search] -> generate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the Router RAG Graph\n",
    "\n",
    "Let's visualize our router RAG workflow to see how the conditional routing works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from IPython.display import Image, display\n\ndisplay(Image(router_rag_graph.get_graph().draw_mermaid_png()))"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the Complete Router RAG System\n",
    "\n",
    "Let's test our router RAG system with various types of queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_router_rag(query: str):\n",
    "    \"\"\"Ask a question to our Router RAG system.\"\"\"\n",
    "    print(f\"\\nQuery: {query}\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # Run the router RAG workflow\n",
    "    result = router_rag_graph.invoke({\"query\": query})\n",
    "    \n",
    "    print(f\"\\nAnswer: {result['answer']}\")\n",
    "    print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with a product recommendation query\n",
    "ask_router_rag(\"I need a lightweight laptop for university. What do you recommend?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with a shipping policy query\n",
    "ask_router_rag(\"How long does shipping take?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with a troubleshooting query\n",
    "ask_router_rag(\"My laptop battery drains very quickly\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the Problematic Questions from Basic RAG\n",
    "\n",
    "Now let's test the same problematic questions from the basic RAG notebook to see how router RAG handles them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# troubleshooting vs product info\n",
    "ask_router_rag(\"ultrabook pro charging ports\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# question about return policy for monitors / no longer returns info from catalog\n",
    "ask_router_rag(\"What's your return policy for monitors?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with web search queries that need current information\n",
    "ask_router_rag(\"Windows 11 blue screen error 0x0000007E - how do I fix this?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This query requires current hardware information not in our database\n",
    "ask_router_rag(\"Whats the latest Nvidia GPU series for gaming?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try your own questions here!\n",
    "# your_question = \"\"\n",
    "# ask_router_rag(your_question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison: Router RAG vs Basic RAG\n",
    "\n",
    "Let's compare how Router RAG improves upon Basic RAG:\n",
    "\n",
    "### Router RAG Advantages:\n",
    "\n",
    "1. **Intent-Aware Routing**: Queries are automatically classified and routed to the most relevant collection\n",
    "2. **Focused Context**: Only relevant documents are retrieved, eliminating noise from unrelated collections\n",
    "3. **Domain Expertise**: Each collection can be optimized for its specific domain (products, support, policies)\n",
    "4. **Better Precision**: Reduced false positives from semantically similar but contextually irrelevant documents\n",
    "5. **Cleaner Answers**: Responses are more focused and less confused by mixed context types\n",
    "6. **Integration with Multiple Data Sources / Web Search**: Current information retrieval for troubleshooting issues not in our database\n",
    "\n",
    "### When Router RAG Excels:\n",
    "\n",
    "- **Domain-Specific Questions**: \"What laptops do you have?\" → Direct to catalog\n",
    "- **Policy Questions**: \"How do returns work?\" → Direct to FAQ\n",
    "- **Technical Support**: \"Screen flickering issue\" → Direct to troubleshooting\n",
    "- **Current Information**: \"Windows 11 blue screen error\" → Direct to web search\n",
    "\n",
    "### Remaining Challenges:\n",
    "\n",
    "- **Multi-Domain & Multi-Hop Queries**: Questions spanning multiple collections, or needing multple steps.\n",
    "- **Router Accuracy**: Misclassification by the router can lead to searching the wrong collection\n",
    "- **Noisy Documents within a Collection**: Even when querying a single index, the retriever can still return noisy / irrelevant documents.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}