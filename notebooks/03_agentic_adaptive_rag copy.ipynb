{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agentic Adaptive RAG with LangGraph\n",
    "\n",
    "In this notebook, we'll build the most sophisticated RAG system yet - one that adapts its strategy based on query complexity, evaluates result quality, and can even rewrite queries for better results.\n",
    "\n",
    "## What is Adaptive RAG?\n",
    "\n",
    "Adaptive RAG goes beyond simple routing by:\n",
    "1. **Analyzing query complexity** to determine the best retrieval strategy\n",
    "2. **Searching multiple collections** when queries span domains\n",
    "3. **Evaluating result quality** and adapting if results are poor\n",
    "4. **Rewriting queries** to improve retrieval when needed\n",
    "5. **Self-correcting** through iterative refinement\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will:\n",
    "- Understand query complexity analysis and strategy selection\n",
    "- Build multi-collection search capabilities\n",
    "- Implement response quality evaluation and grading\n",
    "- Create query rewriting and expansion mechanisms\n",
    "- Design self-correcting RAG workflows\n",
    "- Compare adaptive RAG with simpler approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports\n",
    "\n",
    "We'll need additional imports for the adaptive functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All imports successful!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from typing import List, TypedDict, Literal, Optional\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_community.retrievers import TavilySearchAPIRetriever\n",
    "from langgraph.graph import StateGraph, END\n",
    "from pydantic import BaseModel, Field\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "print(\"All imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API key found!\n",
      "Tavily API key found!\n"
     ]
    }
   ],
   "source": [
    "# Check if OpenAI API key is available\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "if not openai_api_key:\n",
    "    raise ValueError(\"OPENAI_API_KEY environment variable is required\")\n",
    "\n",
    "# Check if Tavily API key is available\n",
    "tavily_api_key = os.getenv(\"TAVILY_API_KEY\")\n",
    "if not tavily_api_key:\n",
    "    raise ValueError(\"TAVILY_API_KEY environment variable is required for web search functionality\")\n",
    "\n",
    "print(\"OpenAI API key found!\")\n",
    "print(\"Tavily API key found!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to ChromaDB Collections\n",
    "\n",
    "We'll use the same separate collections as in the router RAG notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to ChromaDB collections at: ../vector_store/chroma_db_separate\n",
      "catalog: 325 documents\n",
      "faq: 50 documents\n",
      "troubleshooting: 154 documents\n"
     ]
    }
   ],
   "source": [
    "# Initialize embeddings model\n",
    "embeddings = OpenAIEmbeddings(\n",
    "    model=os.getenv(\"OPENAI_EMBEDDING_MODEL\", \"text-embedding-3-small\"),\n",
    "    api_key=openai_api_key\n",
    ")\n",
    "\n",
    "# Path to the separate ChromaDB collections\n",
    "chroma_db_path = Path(\"..\") / \"vector_store\" / \"chroma_db_separate\"\n",
    "\n",
    "# Connect to each collection\n",
    "catalog_store = Chroma(\n",
    "    collection_name=\"techmart_catalog\",\n",
    "    embedding_function=embeddings,\n",
    "    persist_directory=str(chroma_db_path)\n",
    ")\n",
    "\n",
    "faq_store = Chroma(\n",
    "    collection_name=\"techmart_faq\",\n",
    "    embedding_function=embeddings,\n",
    "    persist_directory=str(chroma_db_path)\n",
    ")\n",
    "\n",
    "troubleshooting_store = Chroma(\n",
    "    collection_name=\"techmart_troubleshooting\",\n",
    "    embedding_function=embeddings,\n",
    "    persist_directory=str(chroma_db_path)\n",
    ")\n",
    "\n",
    "# Create a mapping for easy access\n",
    "collections = {\n",
    "    \"catalog\": catalog_store,\n",
    "    \"faq\": faq_store,\n",
    "    \"troubleshooting\": troubleshooting_store\n",
    "}\n",
    "\n",
    "print(f\"Connected to ChromaDB collections at: {chroma_db_path}\")\n",
    "for name, store in collections.items():\n",
    "    print(f\"{name}: {store._collection.count()} documents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Language Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis language model initialized: gpt-4.1\n",
      "Generation language model initialized: gpt-4.1-mini\n",
      "Evaluation language model initialized: gpt-4.1-nano\n"
     ]
    }
   ],
   "source": [
    "# Initialize separate language models for different tasks\n",
    "# Analysis LLM - Most capable model for complex query analysis and decomposition\n",
    "analysis_llm = ChatOpenAI(\n",
    "    model=\"gpt-4.1\",\n",
    "    api_key=openai_api_key,\n",
    ")\n",
    "\n",
    "# Generation LLM - Balanced model for answer generation\n",
    "generation_llm = ChatOpenAI(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    api_key=openai_api_key,\n",
    ")\n",
    "\n",
    "# Evaluation LLM - Fast model for document relevance evaluation\n",
    "evaluation_llm = ChatOpenAI(\n",
    "    model=\"gpt-4.1-nano\",\n",
    "    api_key=openai_api_key,\n",
    ")\n",
    "\n",
    "print(f\"Analysis language model initialized: {analysis_llm.model_name}\")\n",
    "print(f\"Generation language model initialized: {generation_llm.model_name}\")\n",
    "print(f\"Evaluation language model initialized: {evaluation_llm.model_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Adaptive RAG State\n",
    "\n",
    "Our state needs to track the entire adaptive workflow including strategy decisions, multiple retrievals, and quality assessments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adaptive RAG state defined!\n"
     ]
    }
   ],
   "source": [
    "class AdaptiveRAGState(TypedDict):\n",
    "    \"\"\"State for our Adaptive RAG workflow.\"\"\"\n",
    "    # Input\n",
    "    query: str\n",
    "    original_query: str\n",
    "    \n",
    "    # Query decomposition\n",
    "    needs_decomposition: bool\n",
    "    sub_queries: List[str]\n",
    "    execution_plan: str  # \"sequential\" or \"parallel\"\n",
    "    current_sub_query_index: int\n",
    "    sub_query_results: List[dict]  # Results from each sub-query\n",
    "    \n",
    "    # Strategy and routing\n",
    "    search_strategy: str\n",
    "    collections_to_search: List[str]\n",
    "    \n",
    "    # Retrieval results\n",
    "    retrieved_docs: List[Document]\n",
    "    all_retrieved_docs: dict  # Store docs by collection\n",
    "    \n",
    "    # Quality assessment\n",
    "    docs_relevant: bool\n",
    "    quality_score: float\n",
    "    \n",
    "    # Query rewriting\n",
    "    needs_rewrite: bool\n",
    "    rewritten_query: Optional[str]\n",
    "    retry_count: int\n",
    "    \n",
    "    # Output\n",
    "    answer: str\n",
    "    confidence: str\n",
    "\n",
    "print(\"Adaptive RAG state defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query Analysis\n",
    "\n",
    "The first step is analyzing the query to determine the best retrieval strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query analysis system with web search support created using gpt-4.1!\n"
     ]
    }
   ],
   "source": [
    "class QueryAnalysis(BaseModel):\n",
    "    \"\"\"Analysis of query characteristics.\"\"\"\n",
    "    needs_decomposition: bool = Field(\n",
    "        description=\"Whether the query should be broken down into sub-queries\"\n",
    "    )\n",
    "    sub_queries: List[str] = Field(\n",
    "        description=\"List of sub-queries if decomposition is needed\",\n",
    "        default_factory=list\n",
    "    )\n",
    "    execution_plan: Literal[\"sequential\", \"parallel\"] = Field(\n",
    "        description=\"How sub-queries should be executed\",\n",
    "        default=\"parallel\"\n",
    "    )\n",
    "    search_strategy: Literal[\"single_collection\", \"multi_collection\", \"comprehensive\"] = Field(\n",
    "        description=\"Recommended search strategy\"\n",
    "    )\n",
    "    collections_needed: List[Literal[\"catalog\", \"faq\", \"troubleshooting\", \"web_search\"]] = Field(\n",
    "        description=\"Collections that should be searched\"\n",
    "    )\n",
    "    reasoning: str = Field(\n",
    "        description=\"Explanation of the analysis and strategy choice\"\n",
    "    )\n",
    "\n",
    "# Query analysis prompt\n",
    "analysis_prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"You are a query analyzer for TechMart's adaptive RAG system.\n",
    "Analyze the query to determine whether it needs decomposition, and the best retrieval strategy.\n",
    "\n",
    "Available collections:\n",
    "- **catalog**: Product information, specifications, recommendations\n",
    "- **faq**: Customer service, shipping, returns, policies\n",
    "- **troubleshooting**: Technical support, problem diagnosis, solutions for TechMart products\n",
    "- **web_search**: For troubleshooting questions about issues not covered in our internal troubleshooting database, or for getting the latest information about software, drivers, or technical problems that require current information from the internet\n",
    "\n",
    "Query decomposition rules:\n",
    "- **Decompose if**: Query contains multiple distinct questions, has complex AND/OR logic, or spans multiple unrelated domains\n",
    "- **Don't decompose if**: Query is cohesive even if complex, or sub-parts heavily depend on each other\n",
    "\n",
    "Execution plans:\n",
    "- **sequential**: When later sub-queries depend on earlier results (e.g., \"Find gaming laptops, then tell me about warranty for the best one\")\n",
    "- **parallel**: When sub-queries are independent (e.g., \"What gaming laptops do you have and what are your shipping options?\")\n",
    "\n",
    "Search strategies:\n",
    "- **single_collection**: Search one most relevant collection\n",
    "- **multi_collection**: Search 2-3 relevant collections\n",
    "- **comprehensive**: Search all collections for complex/vague queries\n",
    "\n",
    "Collection selection rules:\n",
    "- Use **web_search** for troubleshooting issues that are likely not covered in our limited internal database\n",
    "- Use **web_search** for current software, driver, or OS compatibility issues\n",
    "- Use internal collections (catalog, faq, troubleshooting) for TechMart-specific information\n",
    "\n",
    "Examples:\n",
    "1. \"What gaming laptops do you have and what are your return policies?\" \n",
    "   - Decompose: Yes, Sub-queries: [\"What gaming laptops do you have?\", \"What are your return policies?\"], Execution: parallel, Collections: [\"catalog\", \"faq\"]\n",
    "\n",
    "2. \"I need a laptop under $1000, then tell me how long shipping takes for my choice\"\n",
    "   - Decompose: Yes, Sub-queries: [\"Show me laptops under $1000\", \"How long does shipping take?\"], Execution: sequential, Collections: [\"catalog\", \"faq\"]\n",
    "\n",
    "3. \"What are the specs of the UltraBook Pro 14?\"\n",
    "   - Decompose: No, Collections: [\"catalog\"]\n",
    "\n",
    "4. \"Windows 11 blue screen error 0x0000007E - how do I fix this?\"\n",
    "   - Decompose: No, Collections: [\"web_search\"]\n",
    "\n",
    "5. \"My laptop won't turn on\"\n",
    "   - Decompose: No, Collections: [\"troubleshooting\"] (common issue likely in our database)\n",
    "\n",
    "6. \"Latest NVIDIA driver causing display issues\"\n",
    "   - Decompose: No, Collections: [\"web_search\"] (current driver issue needing web information)\n",
    "\n",
    "Query: {query}\n",
    "\n",
    "Provide your analysis:\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "# Create analysis chain with analysis LLM\n",
    "analysis_chain = analysis_prompt | analysis_llm.with_structured_output(QueryAnalysis)\n",
    "\n",
    "print(\"Query analysis system with web search support created using gpt-4.1!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Query Analysis\n",
    "\n",
    "Let's test our query analyzer with different types of queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Query Analysis with Decomposition and Web Search:\n",
      "==========================================================================================\n",
      "\n",
      "Query: What are the specs of the UltraBook Pro 14?\n",
      "Needs Decomposition: False\n",
      "Strategy: single_collection\n",
      "Collections: ['catalog']\n",
      "Reasoning: The query is singular and focused—it asks for product specifications about a specific laptop model, 'UltraBook Pro 14.' There are no multiple questions, dependencies, or unrelated topics. The most relevant collection for detailed product specs is 'catalog.' No decomposition is required, and a single_collection retrieval strategy suffices.\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Query: What gaming laptops do you have and what are your return policies?\n",
      "Needs Decomposition: True\n",
      "Sub-queries: ['What gaming laptops do you have?', 'What are your return policies?']\n",
      "Execution Plan: parallel\n",
      "Strategy: multi_collection\n",
      "Collections: ['catalog', 'faq']\n",
      "Reasoning: The query contains two distinct questions: one about product availability (gaming laptops) and one about store policies (returns). These are independent and can be answered in parallel. The catalog is needed for gaming laptop information, and the FAQ for return policies. No need for troubleshooting or external web search.\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Query: battery life for zenithbook air 15 vs ultrapook 14 pro\n",
      "Needs Decomposition: True\n",
      "Sub-queries: ['What is the battery life for ZenithBook Air 15?', 'What is the battery life for UltraBook 14 Pro?', 'How do they compare?']\n",
      "Execution Plan: parallel\n",
      "Strategy: multi_collection\n",
      "Collections: ['catalog']\n",
      "Reasoning: The query asks for battery life information for two different products and also implies a comparison between them. While the comparison depends on the battery life details, these details can be retrieved independently for both products in parallel from the catalog. Only the catalog collection is required because this information pertains to official product specifications. No customer service, troubleshooting, or web search is necessary.\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Query: I need a laptop and want to know about Chrome crashes on macOS\n",
      "Needs Decomposition: True\n",
      "Sub-queries: ['I need a laptop', 'I want to know about Chrome crashes on macOS']\n",
      "Execution Plan: parallel\n",
      "Strategy: multi_collection\n",
      "Collections: ['catalog', 'web_search']\n",
      "Reasoning: The query contains two distinct parts: one about purchasing a laptop (product-focused) and one about troubleshooting a software issue on macOS (which is not TechMart-specific and likely needs up-to-date web information). Therefore, decomposition is required. The parts are independent and can be answered in parallel. The search strategy is multi-collection, using the catalog for the laptop request and web_search for the Chrome/macOS issue.\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Test queries of varying complexity including decomposition and web search examples\n",
    "test_queries = [\n",
    "    \"What are the specs of the UltraBook Pro 14?\",  # no decomposition - catalog\n",
    "    \"What gaming laptops do you have and what are your return policies?\",  # parallel decomposition - catalog + faq\n",
    "    \"battery life for zenithbook air 15 vs ultrapook 14 pro\",  # parallel decomposition - catalog + faq\n",
    "    \"I need a laptop and want to know about Chrome crashes on macOS\",  # parallel decomposition - catalog + web_search\n",
    "]\n",
    "\n",
    "print(\"Testing Query Analysis with Decomposition and Web Search:\")\n",
    "print(\"=\" * 90)\n",
    "\n",
    "for query in test_queries:\n",
    "    analysis = analysis_chain.invoke({\"query\": query})\n",
    "    print(f\"\\nQuery: {query}\")\n",
    "    print(f\"Needs Decomposition: {analysis.needs_decomposition}\")\n",
    "    if analysis.needs_decomposition:\n",
    "        print(f\"Sub-queries: {analysis.sub_queries}\")\n",
    "        print(f\"Execution Plan: {analysis.execution_plan}\")\n",
    "    print(f\"Strategy: {analysis.search_strategy}\")\n",
    "    print(f\"Collections: {analysis.collections_needed}\")\n",
    "    print(f\"Reasoning: {analysis.reasoning}\")\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Collection Retrieval\n",
    "\n",
    "We need a system that can search multiple collections and combine results intelligently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi-collection retrieval with web search support created!\n"
     ]
    }
   ],
   "source": [
    "# Initialize Tavily retriever for web search\n",
    "tavily_retriever = TavilySearchAPIRetriever(\n",
    "    api_key=tavily_api_key,\n",
    "    k=5,  # Number of search results to return\n",
    "    include_generated_answer=False,\n",
    "    include_raw_content=False\n",
    ")\n",
    "\n",
    "def retrieve_from_collections(query: str, collection_names: List[str], k: int = 3) -> dict:\n",
    "    \"\"\"Retrieve documents from multiple collections including web search.\"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    for collection_name in collection_names:\n",
    "        if collection_name == \"web_search\":\n",
    "            # Handle web search separately\n",
    "            try:\n",
    "                docs = tavily_retriever.get_relevant_documents(query)\n",
    "                results[collection_name] = docs\n",
    "                print(f\"Retrieved {len(docs)} docs from web search\")\n",
    "            except Exception as e:\n",
    "                print(f\"Web search error: {e}\")\n",
    "                results[collection_name] = []\n",
    "        elif collection_name in collections:\n",
    "            store = collections[collection_name]\n",
    "            docs = store.similarity_search(query, k=k)\n",
    "            results[collection_name] = docs\n",
    "            print(f\"Retrieved {len(docs)} docs from {collection_name}\")\n",
    "        else:\n",
    "            print(f\"Warning: Collection '{collection_name}' not found\")\n",
    "            results[collection_name] = []\n",
    "    \n",
    "    return results\n",
    "\n",
    "def combine_retrieved_docs(all_docs: dict, max_docs: int = 8) -> List[Document]:\n",
    "    \"\"\"Combine documents from multiple collections, maintaining diversity.\"\"\"\n",
    "    combined = []\n",
    "    \n",
    "    # Round-robin through collections to maintain diversity\n",
    "    max_per_collection = max(1, max_docs // len(all_docs))\n",
    "    \n",
    "    for collection_name, docs in all_docs.items():\n",
    "        # Take up to max_per_collection docs from each collection\n",
    "        selected_docs = docs[:max_per_collection]\n",
    "        \n",
    "        # Add collection info to metadata\n",
    "        for doc in selected_docs:\n",
    "            doc.metadata['collection'] = collection_name\n",
    "        \n",
    "        combined.extend(selected_docs)\n",
    "    \n",
    "    return combined[:max_docs]\n",
    "\n",
    "print(\"Multi-collection retrieval with web search support created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document Quality Evaluation\n",
    "\n",
    "We need to evaluate if retrieved documents are relevant and useful for answering the query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document evaluation system created using gpt-4.1-nano!\n"
     ]
    }
   ],
   "source": [
    "class DocumentGrade(BaseModel):\n",
    "    \"\"\"Grade for document relevance.\"\"\"\n",
    "    relevant: Literal[\"yes\", \"no\"] = Field(\n",
    "        description=\"Whether the document is relevant to the query\"\n",
    "    )\n",
    "    confidence: float = Field(\n",
    "        description=\"Confidence score from 0.0 to 1.0\"\n",
    "    )\n",
    "    reasoning: str = Field(\n",
    "        description=\"Brief explanation of the relevance assessment\"\n",
    "    )\n",
    "\n",
    "# Document grading prompt\n",
    "grading_prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"You are evaluating the relevance of a retrieved document to a user query.\n",
    "\n",
    "Query: {query}\n",
    "\n",
    "Document:\n",
    "{document}\n",
    "\n",
    "Instructions:\n",
    "- Mark as \"yes\" if the document contains information that helps answer the query\n",
    "- Mark as \"no\" if the document is not relevant or doesn't help answer the query\n",
    "- Provide a confidence score (0.0 = not confident, 1.0 = very confident)\n",
    "- Give brief reasoning for your assessment\n",
    "\n",
    "Evaluate the document relevance:\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "# Create grading chain with evaluation LLM\n",
    "grading_chain = grading_prompt | evaluation_llm.with_structured_output(DocumentGrade)\n",
    "\n",
    "def evaluate_documents(query: str, documents: List[Document]) -> tuple[List[Document], float]:\n",
    "    \"\"\"Evaluate document relevance and return relevant docs with quality score.\"\"\"\n",
    "    relevant_docs = []\n",
    "    total_confidence = 0.0\n",
    "    \n",
    "    for doc in documents:\n",
    "        # Grade the document using evaluation LLM\n",
    "        grade = grading_chain.invoke({\n",
    "            \"query\": query,\n",
    "            \"document\": doc.page_content\n",
    "        })\n",
    "        \n",
    "        if grade.relevant == \"yes\":\n",
    "            relevant_docs.append(doc)\n",
    "            total_confidence += grade.confidence\n",
    "            print(f\"✓ Relevant doc (confidence: {grade.confidence:.2f}): {grade.reasoning}\")\n",
    "        else:\n",
    "            print(f\"✗ Irrelevant doc: {grade.reasoning}\")\n",
    "    \n",
    "    # Calculate average quality score\n",
    "    quality_score = total_confidence / len(documents) if documents else 0.0\n",
    "    \n",
    "    return relevant_docs, quality_score\n",
    "\n",
    "print(\"Document evaluation system created using gpt-4.1-nano!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query Rewriting and Expansion\n",
    "\n",
    "When initial results are poor, we can rewrite the query to improve retrieval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query rewriting system created using gpt-4.1!\n"
     ]
    }
   ],
   "source": [
    "class QueryRewrite(BaseModel):\n",
    "    \"\"\"Rewritten query for better retrieval.\"\"\"\n",
    "    rewritten_query: str = Field(\n",
    "        description=\"Improved version of the original query\"\n",
    "    )\n",
    "    improvements: str = Field(\n",
    "        description=\"Explanation of what was improved\"\n",
    "    )\n",
    "\n",
    "# Query rewriting prompt\n",
    "rewrite_prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"You are helping improve a query for better document retrieval.\n",
    "The original query didn't return good results, so we need to rewrite it.\n",
    "\n",
    "Original query: {query}\n",
    "Context: This is for a TechMart electronics store with products, customer service info, and troubleshooting guides.\n",
    "\n",
    "Rewriting strategies:\n",
    "- Add more specific terms and context\n",
    "- Expand abbreviations and clarify ambiguous terms\n",
    "- Add relevant synonyms or alternative phrasings\n",
    "- Make implicit requirements explicit\n",
    "\n",
    "Examples:\n",
    "- \"fast computer\" → \"high performance laptop with fast processor and SSD storage\"\n",
    "- \"setup help\" → \"step by step guide for setting up and configuring new computer\"\n",
    "- \"won't work\" → \"troubleshooting device not functioning properly or not turning on\"\n",
    "\n",
    "Provide an improved query:\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "# Create rewriting chain with analysis LLM\n",
    "rewrite_chain = rewrite_prompt | analysis_llm.with_structured_output(QueryRewrite)\n",
    "\n",
    "print(\"Query rewriting system created using gpt-4.1!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adaptive RAG Nodes\n",
    "\n",
    "Now let's create the nodes for our adaptive workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adaptive RAG nodes with updated rewriting rules created!\n"
     ]
    }
   ],
   "source": [
    "def analyze_query(state: AdaptiveRAGState) -> AdaptiveRAGState:\n",
    "    \"\"\"Analyze query complexity and determine search strategy with decomposition.\"\"\"\n",
    "    query = state[\"query\"]\n",
    "    \n",
    "    # Analyze the query\n",
    "    analysis = analysis_chain.invoke({\"query\": query})\n",
    "    \n",
    "    print(f\"Query Analysis:\")\n",
    "    print(f\"  Needs Decomposition: {analysis.needs_decomposition}\")\n",
    "    if analysis.needs_decomposition:\n",
    "        print(f\"  Sub-queries: {analysis.sub_queries}\")\n",
    "        print(f\"  Execution Plan: {analysis.execution_plan}\")\n",
    "    print(f\"  Strategy: {analysis.search_strategy}\")\n",
    "    print(f\"  Collections: {analysis.collections_needed}\")\n",
    "    print(f\"  Reasoning: {analysis.reasoning}\")\n",
    "    \n",
    "    return {\n",
    "        \"original_query\": query,\n",
    "        \"needs_decomposition\": analysis.needs_decomposition,\n",
    "        \"sub_queries\": analysis.sub_queries,\n",
    "        \"execution_plan\": analysis.execution_plan,\n",
    "        \"current_sub_query_index\": 0,\n",
    "        \"sub_query_results\": [],\n",
    "        \"search_strategy\": analysis.search_strategy,\n",
    "        \"collections_to_search\": analysis.collections_needed,\n",
    "        \"retry_count\": state.get(\"retry_count\", 0)\n",
    "    }\n",
    "\n",
    "def execute_sub_query(state: AdaptiveRAGState) -> AdaptiveRAGState:\n",
    "    \"\"\"Execute a single sub-query and store results.\"\"\"\n",
    "    sub_queries = state[\"sub_queries\"]\n",
    "    current_index = state[\"current_sub_query_index\"]\n",
    "    collections_to_search = state[\"collections_to_search\"]\n",
    "    strategy = state[\"search_strategy\"]\n",
    "    \n",
    "    if current_index >= len(sub_queries):\n",
    "        return state  # No more sub-queries to process\n",
    "    \n",
    "    current_sub_query = sub_queries[current_index]\n",
    "    print(f\"\\nExecuting sub-query {current_index + 1}/{len(sub_queries)}: {current_sub_query}\")\n",
    "    \n",
    "    # Determine number of docs per collection based on strategy\n",
    "    if strategy == \"single_collection\":\n",
    "        k_per_collection = 5\n",
    "    elif strategy == \"multi_collection\":\n",
    "        k_per_collection = 3\n",
    "    else:  # comprehensive\n",
    "        k_per_collection = 2\n",
    "    \n",
    "    # Retrieve documents for this sub-query\n",
    "    all_docs = retrieve_from_collections(current_sub_query, collections_to_search, k_per_collection)\n",
    "    combined_docs = combine_retrieved_docs(all_docs)\n",
    "    \n",
    "    # Evaluate quality for this sub-query\n",
    "    print(f\"Evaluating {len(combined_docs)} documents for sub-query...\")\n",
    "    relevant_docs, quality_score = evaluate_documents(current_sub_query, combined_docs)\n",
    "    \n",
    "    # Store results for this sub-query\n",
    "    sub_query_result = {\n",
    "        \"query\": current_sub_query,\n",
    "        \"retrieved_docs\": relevant_docs,\n",
    "        \"quality_score\": quality_score,\n",
    "        \"all_retrieved_docs\": all_docs\n",
    "    }\n",
    "    \n",
    "    # Update state\n",
    "    updated_results = state[\"sub_query_results\"] + [sub_query_result]\n",
    "    \n",
    "    print(f\"Sub-query {current_index + 1} completed:\")\n",
    "    print(f\"  Relevant docs: {len(relevant_docs)}\")\n",
    "    print(f\"  Quality score: {quality_score:.2f}\")\n",
    "    \n",
    "    return {\n",
    "        \"sub_query_results\": updated_results,\n",
    "        \"current_sub_query_index\": current_index + 1,\n",
    "        \"retrieved_docs\": relevant_docs,  # For current sub-query\n",
    "        \"quality_score\": quality_score,\n",
    "        \"docs_relevant\": len(relevant_docs) >= 1  # Updated: Only need 1 relevant doc\n",
    "    }\n",
    "\n",
    "def execute_parallel_sub_queries(state: AdaptiveRAGState) -> AdaptiveRAGState:\n",
    "    \"\"\"Execute all sub-queries in parallel and combine results.\"\"\"\n",
    "    sub_queries = state[\"sub_queries\"]\n",
    "    collections_to_search = state[\"collections_to_search\"]\n",
    "    strategy = state[\"search_strategy\"]\n",
    "    \n",
    "    print(f\"\\nExecuting {len(sub_queries)} sub-queries in parallel:\")\n",
    "    for i, sq in enumerate(sub_queries, 1):\n",
    "        print(f\"  {i}. {sq}\")\n",
    "    \n",
    "    # Determine number of docs per collection\n",
    "    if strategy == \"single_collection\":\n",
    "        k_per_collection = 5\n",
    "    elif strategy == \"multi_collection\":\n",
    "        k_per_collection = 3\n",
    "    else:\n",
    "        k_per_collection = 2\n",
    "    \n",
    "    all_results = []\n",
    "    all_retrieved_docs = []\n",
    "    total_quality = 0.0\n",
    "    \n",
    "    # Execute each sub-query\n",
    "    for i, sub_query in enumerate(sub_queries):\n",
    "        print(f\"\\nProcessing parallel sub-query {i + 1}: {sub_query}\")\n",
    "        \n",
    "        # Retrieve documents\n",
    "        all_docs = retrieve_from_collections(sub_query, collections_to_search, k_per_collection)\n",
    "        combined_docs = combine_retrieved_docs(all_docs)\n",
    "        \n",
    "        # Evaluate quality\n",
    "        relevant_docs, quality_score = evaluate_documents(sub_query, combined_docs)\n",
    "        \n",
    "        # Store results\n",
    "        sub_query_result = {\n",
    "            \"query\": sub_query,\n",
    "            \"retrieved_docs\": relevant_docs,\n",
    "            \"quality_score\": quality_score,\n",
    "            \"all_retrieved_docs\": all_docs\n",
    "        }\n",
    "        all_results.append(sub_query_result)\n",
    "        all_retrieved_docs.extend(relevant_docs)\n",
    "        total_quality += quality_score\n",
    "        \n",
    "        print(f\"  Sub-query {i + 1} results: {len(relevant_docs)} docs, quality: {quality_score:.2f}\")\n",
    "    \n",
    "    # Calculate overall quality\n",
    "    avg_quality = total_quality / len(sub_queries) if sub_queries else 0.0\n",
    "    \n",
    "    print(f\"\\nParallel execution completed:\")\n",
    "    print(f\"  Total documents: {len(all_retrieved_docs)}\")\n",
    "    print(f\"  Average quality: {avg_quality:.2f}\")\n",
    "    \n",
    "    return {\n",
    "        \"sub_query_results\": all_results,\n",
    "        \"retrieved_docs\": all_retrieved_docs,\n",
    "        \"quality_score\": avg_quality,\n",
    "        \"docs_relevant\": len(all_retrieved_docs) >= 1,  # Updated: Only need 1 relevant doc overall\n",
    "        \"current_sub_query_index\": len(sub_queries)  # Mark as complete\n",
    "    }\n",
    "\n",
    "def retrieve_documents(state: AdaptiveRAGState) -> AdaptiveRAGState:\n",
    "    \"\"\"Retrieve documents based on strategy (for non-decomposed queries).\"\"\"\n",
    "    query = state[\"query\"]\n",
    "    collections_to_search = state[\"collections_to_search\"]\n",
    "    strategy = state[\"search_strategy\"]\n",
    "    \n",
    "    # Determine number of docs per collection based on strategy\n",
    "    if strategy == \"single_collection\":\n",
    "        k_per_collection = 5\n",
    "    elif strategy == \"multi_collection\":\n",
    "        k_per_collection = 3\n",
    "    else:  # comprehensive\n",
    "        k_per_collection = 2\n",
    "    \n",
    "    print(f\"Retrieving from collections: {collections_to_search}\")\n",
    "    \n",
    "    # Retrieve from multiple collections\n",
    "    all_docs = retrieve_from_collections(query, collections_to_search, k_per_collection)\n",
    "    \n",
    "    # Combine documents\n",
    "    combined_docs = combine_retrieved_docs(all_docs)\n",
    "    \n",
    "    print(f\"Total documents retrieved: {len(combined_docs)}\")\n",
    "    \n",
    "    return {\n",
    "        \"retrieved_docs\": combined_docs,\n",
    "        \"all_retrieved_docs\": all_docs\n",
    "    }\n",
    "\n",
    "def evaluate_quality(state: AdaptiveRAGState) -> AdaptiveRAGState:\n",
    "    \"\"\"Evaluate the quality of retrieved documents.\"\"\"\n",
    "    query = state[\"query\"]\n",
    "    docs = state[\"retrieved_docs\"]\n",
    "    \n",
    "    print(f\"Evaluating {len(docs)} documents...\")\n",
    "    \n",
    "    # Evaluate document relevance\n",
    "    relevant_docs, quality_score = evaluate_documents(query, docs)\n",
    "    \n",
    "    # Updated: Only require at least 1 relevant document (not 2)\n",
    "    docs_relevant = len(relevant_docs) >= 1\n",
    "    \n",
    "    print(f\"Quality Assessment:\")\n",
    "    print(f\"  Relevant docs: {len(relevant_docs)}/{len(docs)}\")\n",
    "    print(f\"  Quality score: {quality_score:.2f}\")\n",
    "    print(f\"  Results acceptable: {docs_relevant}\")\n",
    "    \n",
    "    return {\n",
    "        \"retrieved_docs\": relevant_docs,\n",
    "        \"docs_relevant\": docs_relevant,\n",
    "        \"quality_score\": quality_score\n",
    "    }\n",
    "\n",
    "def rewrite_query(state: AdaptiveRAGState) -> AdaptiveRAGState:\n",
    "    \"\"\"Rewrite query for better retrieval.\"\"\"\n",
    "    original_query = state[\"original_query\"]\n",
    "    retry_count = state[\"retry_count\"]\n",
    "    \n",
    "    print(f\"Rewriting query (attempt {retry_count + 1})...\")\n",
    "    \n",
    "    # Rewrite the query\n",
    "    rewrite = rewrite_chain.invoke({\"query\": original_query})\n",
    "    \n",
    "    print(f\"Original: {original_query}\")\n",
    "    print(f\"Rewritten: {rewrite.rewritten_query}\")\n",
    "    print(f\"Improvements: {rewrite.improvements}\")\n",
    "    \n",
    "    return {\n",
    "        \"query\": rewrite.rewritten_query,\n",
    "        \"rewritten_query\": rewrite.rewritten_query,\n",
    "        \"needs_rewrite\": False,\n",
    "        \"retry_count\": retry_count + 1\n",
    "    }\n",
    "\n",
    "print(\"Adaptive RAG nodes with updated rewriting rules created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer Generation\n",
    "\n",
    "Enhanced answer generation that considers the adaptive context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adaptive answer generation with graceful failure handling created using gpt-4.1-mini!\n"
     ]
    }
   ],
   "source": [
    "# Enhanced generation prompt for decomposed queries with graceful failure handling\n",
    "adaptive_generate_prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"You are a helpful assistant for TechMart, an electronics retailer.\n",
    "Use the following context to answer the user's question accurately and helpfully.\n",
    "\n",
    "Original Question: {original_question}\n",
    "Query was decomposed: {was_decomposed}\n",
    "{decomposition_info}\n",
    "\n",
    "Search Strategy Used: {search_strategy}\n",
    "Collections Searched: {collections_searched}\n",
    "Quality Score: {quality_score:.2f}\n",
    "Retry Count: {retry_count}\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Instructions:\n",
    "- If context is available, provide a comprehensive answer based on the retrieved information\n",
    "- If the query was decomposed, address each part of the original question\n",
    "- If information spans multiple domains, organize your response clearly\n",
    "- If NO relevant context is found (even after rewrites), politely explain that you don't have specific information about their query in the TechMart database\n",
    "- Suggest alternative ways to get help (contacting customer service, visiting the website, or asking a more specific question)\n",
    "- Be specific and helpful when context is available, mentioning product names and details\n",
    "- If the quality score is low, acknowledge that the information may be limited\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "def generate_adaptive_answer(state: AdaptiveRAGState) -> AdaptiveRAGState:\n",
    "    \"\"\"Generate answer using adaptive context, handling decomposed queries and graceful failure.\"\"\"\n",
    "    original_query = state[\"original_query\"]\n",
    "    needs_decomposition = state[\"needs_decomposition\"]\n",
    "    strategy = state[\"search_strategy\"]\n",
    "    collections = state[\"collections_to_search\"]\n",
    "    quality_score = state[\"quality_score\"]\n",
    "    retry_count = state[\"retry_count\"]\n",
    "    \n",
    "    # Prepare context based on whether query was decomposed\n",
    "    if needs_decomposition and state[\"sub_query_results\"]:\n",
    "        # Handle decomposed query\n",
    "        context_parts = []\n",
    "        decomposition_info = f\"Sub-queries executed ({state['execution_plan']}):\\n\"\n",
    "        \n",
    "        for i, result in enumerate(state[\"sub_query_results\"], 1):\n",
    "            decomposition_info += f\"  {i}. {result['query']}\\n\"\n",
    "            \n",
    "            # Add docs from this sub-query\n",
    "            for doc in result[\"retrieved_docs\"]:\n",
    "                collection = doc.metadata.get('collection', 'unknown')\n",
    "                source = doc.metadata.get('source', 'unknown')\n",
    "                context_parts.append(f\"[SUB-QUERY {i}] [{collection.upper()}] {source}: {doc.page_content}\")\n",
    "        \n",
    "        context_text = \"\\n\\n\".join(context_parts) if context_parts else \"No relevant documents found after multiple search attempts.\"\n",
    "        was_decomposed = \"Yes\"\n",
    "    else:\n",
    "        # Handle regular query\n",
    "        docs = state[\"retrieved_docs\"]\n",
    "        if docs:\n",
    "            context_parts = []\n",
    "            for doc in docs:\n",
    "                collection = doc.metadata.get('collection', 'unknown')\n",
    "                source = doc.metadata.get('source', 'unknown')\n",
    "                context_parts.append(f\"[{collection.upper()}] {source}: {doc.page_content}\")\n",
    "            context_text = \"\\n\\n\".join(context_parts)\n",
    "        else:\n",
    "            context_text = \"No relevant documents found after multiple search attempts.\"\n",
    "        \n",
    "        was_decomposed = \"No\"\n",
    "        decomposition_info = \"\"\n",
    "    \n",
    "    # Generate response using generation LLM\n",
    "    messages = adaptive_generate_prompt.invoke({\n",
    "        \"context\": context_text,\n",
    "        \"original_question\": original_query,\n",
    "        \"was_decomposed\": was_decomposed,\n",
    "        \"decomposition_info\": decomposition_info,\n",
    "        \"search_strategy\": strategy,\n",
    "        \"collections_searched\": \", \".join(collections),\n",
    "        \"quality_score\": quality_score,\n",
    "        \"retry_count\": retry_count\n",
    "    })\n",
    "    \n",
    "    response = generation_llm.invoke(messages)\n",
    "    \n",
    "    # Determine confidence level with updated logic\n",
    "    if needs_decomposition:\n",
    "        # For decomposed queries, consider overall results\n",
    "        total_docs = sum(len(result[\"retrieved_docs\"]) for result in state[\"sub_query_results\"])\n",
    "        if total_docs == 0:\n",
    "            confidence = \"none\"  # No relevant documents found\n",
    "        elif quality_score >= 0.6 and total_docs >= 3:\n",
    "            confidence = \"high\"\n",
    "        elif quality_score >= 0.4 and total_docs >= 1:\n",
    "            confidence = \"medium\"\n",
    "        else:\n",
    "            confidence = \"low\"\n",
    "    else:\n",
    "        # For regular queries\n",
    "        docs = state[\"retrieved_docs\"]\n",
    "        if len(docs) == 0:\n",
    "            confidence = \"none\"  # No relevant documents found\n",
    "        elif quality_score >= 0.7 and len(docs) >= 3:\n",
    "            confidence = \"high\"\n",
    "        elif quality_score >= 0.4 and len(docs) >= 1:\n",
    "            confidence = \"medium\"\n",
    "        else:\n",
    "            confidence = \"low\"\n",
    "    \n",
    "    print(f\"Generated answer with {confidence} confidence using gpt-4.1-mini\")\n",
    "    if confidence == \"none\":\n",
    "        print(f\"No relevant documents found after {retry_count} rewrite attempts\")\n",
    "    \n",
    "    return {\n",
    "        \"answer\": response.content,\n",
    "        \"confidence\": confidence\n",
    "    }\n",
    "\n",
    "print(\"Adaptive answer generation with graceful failure handling created using gpt-4.1-mini!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the Adaptive RAG Graph\n",
    "\n",
    "Now we'll create the complete adaptive workflow with conditional routing and self-correction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adaptive RAG graph with updated rewriting rules compiled successfully!\n"
     ]
    }
   ],
   "source": [
    "# Define routing functions\n",
    "def route_after_analysis(state: AdaptiveRAGState) -> str:\n",
    "    \"\"\"Route after query analysis based on decomposition needs.\"\"\"\n",
    "    needs_decomposition = state[\"needs_decomposition\"]\n",
    "    \n",
    "    if needs_decomposition:\n",
    "        execution_plan = state[\"execution_plan\"]\n",
    "        if execution_plan == \"parallel\":\n",
    "            return \"execute_parallel_sub_queries\"\n",
    "        else:  # sequential\n",
    "            return \"execute_sub_query\"\n",
    "    else:\n",
    "        return \"retrieve_documents\"\n",
    "\n",
    "def route_sequential_execution(state: AdaptiveRAGState) -> str:\n",
    "    \"\"\"Route for sequential sub-query execution.\"\"\"\n",
    "    sub_queries = state[\"sub_queries\"]\n",
    "    current_index = state[\"current_sub_query_index\"]\n",
    "    \n",
    "    if current_index < len(sub_queries):\n",
    "        return \"execute_sub_query\"  # Continue with next sub-query\n",
    "    else:\n",
    "        return \"combine_sub_query_results\"  # All sub-queries completed\n",
    "\n",
    "def should_rewrite_query(state: AdaptiveRAGState) -> str:\n",
    "    \"\"\"Decide if query should be rewritten based on quality - only if NO relevant docs found.\"\"\"\n",
    "    docs_relevant = state[\"docs_relevant\"]\n",
    "    retry_count = state[\"retry_count\"]\n",
    "    max_retries = 3  # Updated: Allow up to 3 rewrites\n",
    "    \n",
    "    # Only rewrite if NO relevant documents found AND haven't exceeded max retries\n",
    "    if not docs_relevant and retry_count < max_retries:\n",
    "        print(f\"No relevant documents found. Attempting rewrite {retry_count + 1}/{max_retries}\")\n",
    "        return \"rewrite_query\"\n",
    "    else:\n",
    "        if retry_count >= max_retries:\n",
    "            print(f\"Maximum rewrites ({max_retries}) reached. Proceeding with available information.\")\n",
    "        return \"generate_answer\"\n",
    "\n",
    "def combine_sub_query_results(state: AdaptiveRAGState) -> AdaptiveRAGState:\n",
    "    \"\"\"Combine results from all sequential sub-queries.\"\"\"\n",
    "    sub_query_results = state[\"sub_query_results\"]\n",
    "    \n",
    "    print(f\"\\nCombining results from {len(sub_query_results)} sequential sub-queries\")\n",
    "    \n",
    "    # Combine all documents\n",
    "    all_docs = []\n",
    "    total_quality = 0.0\n",
    "    \n",
    "    for result in sub_query_results:\n",
    "        all_docs.extend(result[\"retrieved_docs\"])\n",
    "        total_quality += result[\"quality_score\"]\n",
    "    \n",
    "    # Calculate average quality\n",
    "    avg_quality = total_quality / len(sub_query_results) if sub_query_results else 0.0\n",
    "    \n",
    "    print(f\"Sequential execution completed:\")\n",
    "    print(f\"  Total documents: {len(all_docs)}\")\n",
    "    print(f\"  Average quality: {avg_quality:.2f}\")\n",
    "    \n",
    "    return {\n",
    "        \"retrieved_docs\": all_docs,\n",
    "        \"quality_score\": avg_quality,\n",
    "        \"docs_relevant\": len(all_docs) >= 1  # Updated: Only need 1 relevant doc\n",
    "    }\n",
    "\n",
    "# Create the graph builder\n",
    "graph_builder = StateGraph(AdaptiveRAGState)\n",
    "\n",
    "# Add all nodes\n",
    "graph_builder.add_node(\"analyze_query\", analyze_query)\n",
    "graph_builder.add_node(\"retrieve_documents\", retrieve_documents)\n",
    "graph_builder.add_node(\"execute_sub_query\", execute_sub_query)\n",
    "graph_builder.add_node(\"execute_parallel_sub_queries\", execute_parallel_sub_queries)\n",
    "graph_builder.add_node(\"combine_sub_query_results\", combine_sub_query_results)\n",
    "graph_builder.add_node(\"evaluate_quality\", evaluate_quality)\n",
    "graph_builder.add_node(\"rewrite_query\", rewrite_query)\n",
    "graph_builder.add_node(\"generate_answer\", generate_adaptive_answer)\n",
    "\n",
    "# Set entry point\n",
    "graph_builder.set_entry_point(\"analyze_query\")\n",
    "\n",
    "# Route after analysis based on decomposition needs\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"analyze_query\",\n",
    "    route_after_analysis,\n",
    "    {\n",
    "        \"retrieve_documents\": \"retrieve_documents\",\n",
    "        \"execute_sub_query\": \"execute_sub_query\",\n",
    "        \"execute_parallel_sub_queries\": \"execute_parallel_sub_queries\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# Regular retrieval flow (for non-decomposed queries)\n",
    "graph_builder.add_edge(\"retrieve_documents\", \"evaluate_quality\")\n",
    "\n",
    "# Sequential sub-query execution flow\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"execute_sub_query\",\n",
    "    route_sequential_execution,\n",
    "    {\n",
    "        \"execute_sub_query\": \"execute_sub_query\",  # Continue with next sub-query\n",
    "        \"combine_sub_query_results\": \"combine_sub_query_results\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# After combining sequential results, evaluate quality\n",
    "graph_builder.add_edge(\"combine_sub_query_results\", \"evaluate_quality\")\n",
    "\n",
    "# Parallel sub-query execution goes directly to evaluation\n",
    "# (quality evaluation is built into the parallel execution)\n",
    "graph_builder.add_edge(\"execute_parallel_sub_queries\", \"evaluate_quality\")\n",
    "\n",
    "# Quality evaluation routing - updated logic\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"evaluate_quality\",\n",
    "    should_rewrite_query,\n",
    "    {\n",
    "        \"rewrite_query\": \"rewrite_query\",\n",
    "        \"generate_answer\": \"generate_answer\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# After rewriting, go back to analysis\n",
    "graph_builder.add_edge(\"rewrite_query\", \"analyze_query\")\n",
    "\n",
    "# Generate answer is the end\n",
    "graph_builder.add_edge(\"generate_answer\", END)\n",
    "\n",
    "# Compile the graph\n",
    "adaptive_rag_graph = graph_builder.compile()\n",
    "\n",
    "print(\"Adaptive RAG graph with updated rewriting rules compiled successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the Adaptive RAG Graph\n",
    "\n",
    "Let's visualize our sophisticated adaptive workflow to see how the self-correcting logic works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(adaptive_rag_graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the Adaptive RAG System\n",
    "\n",
    "Let's test our adaptive system with various types of queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "QUERY: Do you have bluetooth headphones and how fast can they be shipped within the US?\n",
      "================================================================================\n",
      "Query Analysis:\n",
      "  Complexity: medium\n",
      "  Needs Decomposition: True\n",
      "  Sub-queries: ['Do you have bluetooth headphones?', 'How fast can bluetooth headphones be shipped within the US?']\n",
      "  Execution Plan: sequential\n",
      "  Strategy: multi_collection\n",
      "  Collections: ['catalog', 'faq']\n",
      "  Reasoning: The query contains two distinct questions: product availability (catalog) and shipping speed (faq). The second question depends on the first, as shipping information is only relevant if the product is available. Therefore, decomposition is needed with a sequential execution plan. Both the catalog and faq collections are required, making this a multi-collection search. The overall complexity is medium, as it spans two domains but is not highly complex.\n",
      "\n",
      "Executing sub-query 1/2: Do you have bluetooth headphones?\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "Error getting collection: Database error: error returned from database: (code: 14) unable to open database file",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mInternalError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[64]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m     12\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m=\u001b[39m\u001b[33m'\u001b[39m*\u001b[32m80\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# Test with a simple, clear query (no decomposition)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m \u001b[43mask_adaptive_rag\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mDo you have bluetooth headphones and how fast can they be shipped within the US?\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[64]\u001b[39m\u001b[32m, line 8\u001b[39m, in \u001b[36mask_adaptive_rag\u001b[39m\u001b[34m(query)\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m=\u001b[39m\u001b[33m'\u001b[39m*\u001b[32m80\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Run the adaptive RAG workflow\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m result = \u001b[43madaptive_rag_graph\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mquery\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mFINAL ANSWER (Confidence: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult[\u001b[33m'\u001b[39m\u001b[33mconfidence\u001b[39m\u001b[33m'\u001b[39m].upper()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m):\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     11\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult[\u001b[33m'\u001b[39m\u001b[33manswer\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/active/projects/agentic_rag_with_langgraph/.venv/lib/python3.12/site-packages/langgraph/pregel/__init__.py:2844\u001b[39m, in \u001b[36mPregel.invoke\u001b[39m\u001b[34m(self, input, config, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, **kwargs)\u001b[39m\n\u001b[32m   2841\u001b[39m chunks: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] | Any] = []\n\u001b[32m   2842\u001b[39m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] = []\n\u001b[32m-> \u001b[39m\u001b[32m2844\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2845\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   2846\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2847\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mupdates\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m   2848\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m   2849\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2850\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2851\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2852\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2853\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2854\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2855\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2856\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[32m   2857\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/active/projects/agentic_rag_with_langgraph/.venv/lib/python3.12/site-packages/langgraph/pregel/__init__.py:2534\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, subgraphs)\u001b[39m\n\u001b[32m   2532\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m loop.match_cached_writes():\n\u001b[32m   2533\u001b[39m     loop.output_writes(task.id, task.writes, cached=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m2534\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2535\u001b[39m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrites\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2536\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2537\u001b[39m \u001b[43m    \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2538\u001b[39m \u001b[43m    \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43maccept_push\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2539\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2540\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[32m   2541\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_output\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2542\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubgraphs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqueue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mEmpty\u001b[49m\n\u001b[32m   2543\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2544\u001b[39m loop.after_tick()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[60]\u001b[39m\u001b[32m, line 53\u001b[39m, in \u001b[36mexecute_sub_query\u001b[39m\u001b[34m(state)\u001b[39m\n\u001b[32m     50\u001b[39m     k_per_collection = \u001b[32m2\u001b[39m\n\u001b[32m     52\u001b[39m \u001b[38;5;66;03m# Retrieve documents for this sub-query\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m all_docs = \u001b[43mretrieve_from_collections\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcurrent_sub_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollections_to_search\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk_per_collection\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     54\u001b[39m combined_docs = combine_retrieved_docs(all_docs)\n\u001b[32m     56\u001b[39m \u001b[38;5;66;03m# Evaluate quality for this sub-query\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[57]\u001b[39m\u001b[32m, line 8\u001b[39m, in \u001b[36mretrieve_from_collections\u001b[39m\u001b[34m(query, collection_names, k)\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m collection_name \u001b[38;5;129;01min\u001b[39;00m collections:\n\u001b[32m      7\u001b[39m     store = collections[collection_name]\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m     docs = \u001b[43mstore\u001b[49m\u001b[43m.\u001b[49m\u001b[43msimilarity_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m=\u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m     results[collection_name] = docs\n\u001b[32m     10\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mRetrieved \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(docs)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m docs from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcollection_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/active/projects/agentic_rag_with_langgraph/.venv/lib/python3.12/site-packages/langchain_chroma/vectorstores.py:603\u001b[39m, in \u001b[36mChroma.similarity_search\u001b[39m\u001b[34m(self, query, k, filter, **kwargs)\u001b[39m\n\u001b[32m    585\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msimilarity_search\u001b[39m(\n\u001b[32m    586\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    587\u001b[39m     query: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    590\u001b[39m     **kwargs: Any,\n\u001b[32m    591\u001b[39m ) -> \u001b[38;5;28mlist\u001b[39m[Document]:\n\u001b[32m    592\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Run similarity search with Chroma.\u001b[39;00m\n\u001b[32m    593\u001b[39m \n\u001b[32m    594\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    601\u001b[39m \u001b[33;03m        List of documents most similar to the query text.\u001b[39;00m\n\u001b[32m    602\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m603\u001b[39m     docs_and_scores = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msimilarity_search_with_score\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    604\u001b[39m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    605\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    606\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m [doc \u001b[38;5;28;01mfor\u001b[39;00m doc, _ \u001b[38;5;129;01min\u001b[39;00m docs_and_scores]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/active/projects/agentic_rag_with_langgraph/.venv/lib/python3.12/site-packages/langchain_chroma/vectorstores.py:701\u001b[39m, in \u001b[36mChroma.similarity_search_with_score\u001b[39m\u001b[34m(self, query, k, filter, where_document, **kwargs)\u001b[39m\n\u001b[32m    699\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    700\u001b[39m     query_embedding = \u001b[38;5;28mself\u001b[39m._embedding_function.embed_query(query)\n\u001b[32m--> \u001b[39m\u001b[32m701\u001b[39m     results = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__query_collection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    702\u001b[39m \u001b[43m        \u001b[49m\u001b[43mquery_embeddings\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mquery_embedding\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    703\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_results\u001b[49m\u001b[43m=\u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    704\u001b[39m \u001b[43m        \u001b[49m\u001b[43mwhere\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    705\u001b[39m \u001b[43m        \u001b[49m\u001b[43mwhere_document\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwhere_document\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    706\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    707\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    709\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m _results_to_docs_and_scores(results)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/active/projects/agentic_rag_with_langgraph/.venv/lib/python3.12/site-packages/langchain_core/utils/utils.py:54\u001b[39m, in \u001b[36mxor_args.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     48\u001b[39m     msg = (\n\u001b[32m     49\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mExactly one argument in each of the following\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     50\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m groups must be defined:\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     51\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m.join(invalid_group_names)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     52\u001b[39m     )\n\u001b[32m     53\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[32m---> \u001b[39m\u001b[32m54\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/active/projects/agentic_rag_with_langgraph/.venv/lib/python3.12/site-packages/langchain_chroma/vectorstores.py:393\u001b[39m, in \u001b[36mChroma.__query_collection\u001b[39m\u001b[34m(self, query_texts, query_embeddings, n_results, where, where_document, **kwargs)\u001b[39m\n\u001b[32m    365\u001b[39m \u001b[38;5;129m@xor_args\u001b[39m((\u001b[33m\"\u001b[39m\u001b[33mquery_texts\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mquery_embeddings\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m    366\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__query_collection\u001b[39m(\n\u001b[32m    367\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    373\u001b[39m     **kwargs: Any,\n\u001b[32m    374\u001b[39m ) -> Union[\u001b[38;5;28mlist\u001b[39m[Document], chromadb.QueryResult]:\n\u001b[32m    375\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Query the chroma collection.\u001b[39;00m\n\u001b[32m    376\u001b[39m \n\u001b[32m    377\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    391\u001b[39m \u001b[33;03m    See more: https://docs.trychroma.com/reference/py-collection#query\u001b[39;00m\n\u001b[32m    392\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m393\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_collection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    394\u001b[39m \u001b[43m        \u001b[49m\u001b[43mquery_texts\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquery_texts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    395\u001b[39m \u001b[43m        \u001b[49m\u001b[43mquery_embeddings\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquery_embeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[32m    396\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_results\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_results\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    397\u001b[39m \u001b[43m        \u001b[49m\u001b[43mwhere\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwhere\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[32m    398\u001b[39m \u001b[43m        \u001b[49m\u001b[43mwhere_document\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwhere_document\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[32m    399\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    400\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/active/projects/agentic_rag_with_langgraph/.venv/lib/python3.12/site-packages/chromadb/api/models/Collection.py:221\u001b[39m, in \u001b[36mCollection.query\u001b[39m\u001b[34m(self, query_embeddings, query_texts, query_images, query_uris, ids, n_results, where, where_document, include)\u001b[39m\n\u001b[32m    185\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Get the n_results nearest neighbor embeddings for provided query_embeddings or query_texts.\u001b[39;00m\n\u001b[32m    186\u001b[39m \n\u001b[32m    187\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    206\u001b[39m \n\u001b[32m    207\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    209\u001b[39m query_request = \u001b[38;5;28mself\u001b[39m._validate_and_prepare_query_request(\n\u001b[32m    210\u001b[39m     query_embeddings=query_embeddings,\n\u001b[32m    211\u001b[39m     query_texts=query_texts,\n\u001b[32m   (...)\u001b[39m\u001b[32m    218\u001b[39m     include=include,\n\u001b[32m    219\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m221\u001b[39m query_results = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_query\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    222\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcollection_id\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    223\u001b[39m \u001b[43m    \u001b[49m\u001b[43mids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquery_request\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mids\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    224\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquery_embeddings\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquery_request\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43membeddings\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    225\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_results\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquery_request\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mn_results\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    226\u001b[39m \u001b[43m    \u001b[49m\u001b[43mwhere\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquery_request\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mwhere\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    227\u001b[39m \u001b[43m    \u001b[49m\u001b[43mwhere_document\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquery_request\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mwhere_document\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    228\u001b[39m \u001b[43m    \u001b[49m\u001b[43minclude\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquery_request\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minclude\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    229\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtenant\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtenant\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    230\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdatabase\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdatabase\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    231\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    233\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._transform_query_response(\n\u001b[32m    234\u001b[39m     response=query_results, include=query_request[\u001b[33m\"\u001b[39m\u001b[33minclude\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    235\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/active/projects/agentic_rag_with_langgraph/.venv/lib/python3.12/site-packages/chromadb/api/rust.py:505\u001b[39m, in \u001b[36mRustBindingsAPI._query\u001b[39m\u001b[34m(self, collection_id, query_embeddings, ids, n_results, where, where_document, include, tenant, database)\u001b[39m\n\u001b[32m    489\u001b[39m filtered_ids_amount = \u001b[38;5;28mlen\u001b[39m(ids) \u001b[38;5;28;01mif\u001b[39;00m ids \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m0\u001b[39m\n\u001b[32m    490\u001b[39m \u001b[38;5;28mself\u001b[39m.product_telemetry_client.capture(\n\u001b[32m    491\u001b[39m     CollectionQueryEvent(\n\u001b[32m    492\u001b[39m         collection_uuid=\u001b[38;5;28mstr\u001b[39m(collection_id),\n\u001b[32m   (...)\u001b[39m\u001b[32m    502\u001b[39m     )\n\u001b[32m    503\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m505\u001b[39m rust_response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbindings\u001b[49m\u001b[43m.\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    506\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcollection_id\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    507\u001b[39m \u001b[43m    \u001b[49m\u001b[43mids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    508\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquery_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    509\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_results\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    510\u001b[39m \u001b[43m    \u001b[49m\u001b[43mjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdumps\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    511\u001b[39m \u001b[43m    \u001b[49m\u001b[43mjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdumps\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwhere_document\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mwhere_document\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    512\u001b[39m \u001b[43m    \u001b[49m\u001b[43minclude\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    513\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtenant\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    514\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdatabase\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    515\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    517\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m QueryResult(\n\u001b[32m    518\u001b[39m     ids=rust_response.ids,\n\u001b[32m    519\u001b[39m     embeddings=rust_response.embeddings,\n\u001b[32m   (...)\u001b[39m\u001b[32m    525\u001b[39m     distances=rust_response.distances,\n\u001b[32m    526\u001b[39m )\n",
      "\u001b[31mInternalError\u001b[39m: Error getting collection: Database error: error returned from database: (code: 14) unable to open database file",
      "During task with name 'execute_sub_query' and id 'f7512f9e-790b-4381-0313-b1d07e1fa7f2'"
     ]
    }
   ],
   "source": [
    "def ask_adaptive_rag(query: str):\n",
    "    \"\"\"Ask a question to our Adaptive RAG system.\"\"\"\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"QUERY: {query}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    # Run the adaptive RAG workflow\n",
    "    result = adaptive_rag_graph.invoke({\"query\": query})\n",
    "    \n",
    "    print(f\"\\nFINAL ANSWER (Confidence: {result['confidence'].upper()}):\")\n",
    "    print(f\"{result['answer']}\")\n",
    "    print(f\"{'='*80}\")\n",
    "\n",
    "# Test with a simple, clear query (no decomposition)\n",
    "ask_adaptive_rag(\"Do you have bluetooth headphones and how fast can they be shipped within the US?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with parallel decomposition query\n",
    "ask_adaptive_rag(\"What gaming laptops do you have and what are your return policies?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with sequential decomposition query\n",
    "ask_adaptive_rag(\"Show me laptops under $1500, then tell me shipping options for the best one\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with web search query that needs current information\n",
    "ask_adaptive_rag(\"Windows 11 blue screen error 0x0000007E - how do I fix this?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Mixed Queries (Internal + Web Search)\n",
    "\n",
    "Let's test queries that require both internal collections and web search through decomposition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test complex query mixing internal collections and web search\n",
    "ask_adaptive_rag(\"I need a laptop for programming and want to know how to fix Chrome crashes on latest macOS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test another mixed query\n",
    "ask_adaptive_rag(\"What gaming desktops do you have and how do I fix latest NVIDIA driver issues?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Very vague query\n",
    "ask_adaptive_rag(\"I need something fast\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive Testing\n",
    "\n",
    "Try your own complex queries to see how the adaptive system handles them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try your own complex query here!\n",
    "your_question = \"I'm a student who needs a computer setup for programming and gaming, but I'm on a budget and need to know about warranty and support options\"\n",
    "ask_adaptive_rag(your_question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison: Evolution of RAG Approaches\n",
    "\n",
    "Let's compare all three approaches we've built:\n",
    "\n",
    "### Basic RAG (Notebook 1)\n",
    "**Approach**: Single collection, fixed retrieval strategy\n",
    "- **Strengths**: Simple, fast, works for clear single-domain queries\n",
    "- **Weaknesses**: Context pollution, no domain awareness, fixed strategy, no current information access\n",
    "- **Best for**: Simple, unambiguous queries in single domain\n",
    "\n",
    "### Router RAG (Notebook 2)\n",
    "**Approach**: Intent-based routing to appropriate collection or web search\n",
    "- **Strengths**: Domain-specific retrieval, eliminates context pollution, good for clear intent, web search for current info\n",
    "- **Weaknesses**: Single collection limit, no quality assessment, no self-correction, handles only single questions\n",
    "- **Best for**: Clear domain-specific queries with obvious intent, including current information needs\n",
    "\n",
    "### Adaptive RAG with Query Decomposition + Web Search (Notebook 3)\n",
    "**Approach**: Dynamic strategy selection with query decomposition, quality assessment, self-correction, and web search integration\n",
    "- **Strengths**: \n",
    "  - **Query Decomposition**: Breaks complex multi-part questions into manageable sub-queries\n",
    "  - **Parallel/Sequential Execution**: Optimizes sub-query execution based on dependencies\n",
    "  - **Multi-collection search** for complex queries including web search\n",
    "  - **Web Search Integration**: Access to current information for troubleshooting and technical issues\n",
    "  - **Quality evaluation** of retrieved documents\n",
    "  - **Query rewriting** for better results (conservative approach)\n",
    "  - **Self-correction** through iterative improvement\n",
    "  - **Confidence scoring** for answer reliability\n",
    "  - **Graceful failure** when no information is found\n",
    "- **Weaknesses**: More complex, higher latency, more API calls\n",
    "- **Best for**: Complex, multi-domain, multi-part, or ambiguous queries requiring both internal knowledge and current information\n",
    "\n",
    "### When to Use Each Approach:\n",
    "\n",
    "**Basic RAG**: \n",
    "- Simple applications with homogeneous data\n",
    "- When speed is critical and queries are predictable\n",
    "- Prototype or proof-of-concept development\n",
    "\n",
    "**Router RAG**: \n",
    "- Multi-domain applications with clear, single-question query patterns\n",
    "- When you need domain expertise and current information access\n",
    "- Good balance of accuracy and performance for straightforward questions\n",
    "\n",
    "**Adaptive RAG with Decomposition + Web Search**: \n",
    "- Complex applications with diverse, unpredictable, multi-part queries\n",
    "- When answer quality is more important than speed\n",
    "- Applications requiring high reliability and self-correction\n",
    "- Systems handling compound questions like \"What products do you have AND what are current software issues?\"\n",
    "- Workflows requiring sequential reasoning and current information access\n",
    "- Enterprise systems needing both internal knowledge and real-time troubleshooting\n",
    "\n",
    "### Key Innovations in Adaptive RAG with Decomposition + Web Search:\n",
    "\n",
    "1. **Query Decomposition Analysis**: Identifies when complex queries should be broken down\n",
    "2. **Execution Planning**: Determines whether sub-queries should run sequentially or in parallel\n",
    "3. **Parallel Execution**: Runs independent sub-queries simultaneously for efficiency\n",
    "4. **Sequential Execution**: Handles dependent sub-queries in proper order\n",
    "5. **Sub-Query Result Combination**: Intelligently merges results from multiple sub-queries\n",
    "6. **Multi-Collection Retrieval**: Can search multiple domains simultaneously\n",
    "7. **Web Search Integration**: Access to current information via Tavily for real-time troubleshooting\n",
    "8. **Document Quality Grading**: Evaluates relevance of retrieved documents\n",
    "9. **Conservative Query Rewriting**: Only rewrites when NO relevant docs found, up to 3 attempts\n",
    "10. **Graceful Failure Handling**: Provides helpful responses even when no information is found\n",
    "11. **Self-Correction**: Iteratively improves results through feedback loops\n",
    "12. **Confidence Assessment**: Provides transparency about answer reliability\n",
    "\n",
    "### Query Decomposition + Web Search Examples:\n",
    "\n",
    "**Mixed Source Parallel Decomposition**:\n",
    "- \"I need a laptop for programming and want to know how to fix Chrome crashes on latest macOS\"\n",
    "- Breaks into: [\"Show me laptops suitable for programming\", \"How to fix Chrome crashes on latest macOS\"]\n",
    "- Sources: [catalog] + [web_search]\n",
    "\n",
    "**Internal + Current Information**:\n",
    "- \"What gaming desktops do you have and how do I fix latest NVIDIA driver issues?\"\n",
    "- Breaks into: [\"What gaming desktops do you have?\", \"How to fix latest NVIDIA driver issues?\"]\n",
    "- Sources: [catalog] + [web_search]\n",
    "\n",
    "**Current Troubleshooting**:\n",
    "- \"Windows 11 blue screen error 0x0000007E - how do I fix this?\"\n",
    "- No decomposition needed, routes to: [web_search]\n",
    "\n",
    "This represents the most advanced agentic RAG system combining internal knowledge with real-time information access!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Congratulations! You've built a sophisticated adaptive RAG system with query decomposition and web search integration that represents the current state-of-the-art in agentic information retrieval.\n",
    "\n",
    "### What We Built\n",
    "1. **Query Complexity Analysis**: Automatic assessment of query characteristics and optimal strategy selection\n",
    "2. **Query Decomposition System**: Intelligent breakdown of complex multi-part queries into manageable sub-queries\n",
    "3. **Execution Planning**: Dynamic determination of parallel vs sequential execution based on query dependencies\n",
    "4. **Multi-Collection Retrieval**: Intelligent searching across multiple specialized data sources\n",
    "5. **Web Search Integration**: Real-time information access via Tavily for current troubleshooting and technical issues\n",
    "6. **Document Quality Evaluation**: Automated relevance grading with confidence scoring\n",
    "7. **Conservative Query Rewriting**: Smart rewriting only when no relevant docs found, with graceful failure\n",
    "8. **Self-Correcting Workflow**: Iterative refinement based on quality feedback\n",
    "9. **Adaptive Answer Generation**: Context-aware response creation with confidence indicators\n",
    "\n",
    "### Key Concepts Learned\n",
    "- **Query Decomposition**: Breaking complex questions into simpler, answerable parts\n",
    "- **Execution Planning**: Optimizing sub-query execution based on dependencies\n",
    "- **Parallel vs Sequential Processing**: When to run sub-queries simultaneously vs in order\n",
    "- **Web Search Integration**: Seamlessly combining internal knowledge with real-time information\n",
    "- **Adaptive Strategy Selection**: Choosing retrieval approaches based on query characteristics\n",
    "- **Quality-Driven Workflows**: Using feedback loops to improve results\n",
    "- **Multi-Source Integration**: Combining information from diverse collections and web search\n",
    "- **Conservative Rewriting**: Only rewriting when absolutely necessary to avoid over-processing\n",
    "- **Graceful Failure**: Providing helpful responses even when no information is found\n",
    "- **Confidence Modeling**: Providing transparency about result reliability\n",
    "\n",
    "### Technical Achievements\n",
    "- Complex conditional routing in LangGraph with decomposition and web search pathways\n",
    "- Structured LLM outputs for reliable decision making and query analysis\n",
    "- Document diversity maintenance across collections and web results\n",
    "- Conservative rewriting logic with up to 3 attempts and graceful failure\n",
    "- Multi-dimensional quality assessment across different source types\n",
    "- Dynamic workflow adaptation based on query complexity and dependencies\n",
    "- Seamless integration of real-time web search with internal knowledge bases\n",
    "\n",
    "### Query Decomposition + Web Search Innovation\n",
    "The decomposition system with web search handles complex scenarios like:\n",
    "- **Mixed source questions**: \"I need a laptop and want to know about Chrome crashes\"\n",
    "- **Sequential dependencies with current info**: \"Find laptops, then tell me about latest driver issues\"\n",
    "- **Independent parallel queries**: \"Show me headphones and current Bluetooth problems\"\n",
    "- **Complex reasoning with real-time data**: Breaking down multi-step requests requiring current information\n",
    "\n",
    "### Real-World Applications\n",
    "This adaptive RAG approach with decomposition and web search is suitable for:\n",
    "- **Enterprise Knowledge Management**: Complex internal documentation with real-time troubleshooting\n",
    "- **Customer Support Platforms**: Multi-domain help systems with access to current solutions\n",
    "- **Technical Support Systems**: Combining product knowledge with latest troubleshooting information\n",
    "- **Research Assistants**: Academic or professional research requiring both historical and current data\n",
    "- **E-commerce Platforms**: Product information combined with current compatibility and issue resolution\n",
    "- **Educational Systems**: Learning platforms needing both curriculum content and current technical information\n",
    "- **IT Help Desk Systems**: Internal knowledge combined with latest patches, updates, and solutions\n",
    "\n",
    "### Performance Benefits\n",
    "- **Comprehensive Coverage**: Handles compound questions spanning internal and current information\n",
    "- **Optimized Execution**: Parallel processing where possible, sequential where necessary\n",
    "- **Higher Accuracy**: Focused sub-queries reduce context pollution while accessing current data\n",
    "- **Real-time Relevance**: Web search ensures up-to-date information for technical issues\n",
    "- **Conservative Processing**: Avoids unnecessary rewrites while ensuring quality results\n",
    "- **Improved User Experience**: Natural handling of complex, multi-part questions with current information\n",
    "- **Scalable Architecture**: Can handle increasingly complex query patterns with real-time data needs\n",
    "\n",
    "You've now mastered the complete spectrum of RAG architectures, from basic retrieval to sophisticated adaptive systems with query decomposition and web search integration. These techniques form the foundation for building truly intelligent, responsive AI applications that can handle the complexity and multi-faceted nature of real-world information needs while staying current with the latest information.\n",
    "\n",
    "The journey from basic RAG to adaptive RAG with decomposition and web search demonstrates the power of agentic AI - systems that don't just follow fixed patterns, but actively analyze, plan, adapt, and improve their own performance while handling complex, multi-part queries and seamlessly integrating both internal knowledge and real-time information from the web!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
